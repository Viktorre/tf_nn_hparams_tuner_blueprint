{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsHV-7cpVkyK"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:03<00:00,  3.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensorboard --logdir logs_20220606-130014 --port 1300\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np # for math and arrays\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"C:/Users/reifv/root/Heidelberg Master/vs_codes/tf_nn_hparams_tuner_blueprint/data/diabetes_data.csv\", delimiter=\";\")\n",
        "data = pd.concat([data, pd.get_dummies(data['gender'], prefix='Label')], axis=1)\n",
        "data.pop(\"gender\")\n",
        "train_dataset, temp_test_dataset =  train_test_split(data, test_size=0.3,random_state=42)\n",
        "test_dataset, valid_dataset =  train_test_split(temp_test_dataset, test_size=0.5,random_state=42)\n",
        "train_labels = train_dataset.pop('class')\n",
        "test_labels = test_dataset.pop('class')\n",
        "valid_labels = valid_dataset.pop('class')\n",
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "normed_train_data = pd.DataFrame(StandardScaler().fit_transform(train_dataset), columns=train_dataset.columns, index=train_dataset.index)\n",
        "normed_test_data = pd.DataFrame(StandardScaler().fit_transform(test_dataset), columns=test_dataset.columns, index=test_dataset.index)\n",
        "normed_valid_data = pd.DataFrame(StandardScaler().fit_transform(valid_dataset), columns=valid_dataset.columns, index=valid_dataset.index)\n",
        "x_train, y_train, x_valid, y_valid = normed_train_data, train_labels, normed_valid_data, valid_labels\n",
        "\n",
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([5]))\n",
        "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1]))\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
        "HP_LR = hp.HParam('lr', hp.Discrete([0.0001]))\n",
        "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([2]))\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "# HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32,64,128,256,1000,2000]))\n",
        "# HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1,2,3,4,5]))\n",
        "# # HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
        "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
        "# HP_LR = hp.HParam('lr', hp.Discrete([0.1,0.01,0.001,0.0001,]))\n",
        "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([1,32,256]))\n",
        "# METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "# HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32,64,128,256,1000]))\n",
        "# HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1,2,3,4]))\n",
        "# HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
        "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
        "# HP_LR = hp.HParam('lr', hp.Discrete([0.001,0.0001,]))\n",
        "# HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([1,2,16,32,64]))\n",
        "# METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "log_name = 'logs_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'/hparam_tuning'\n",
        "\n",
        "with tf.summary.create_file_writer(log_name).as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_NUM_LAYERS, HP_OPTIMIZER, HP_LR, HP_BATCH_SIZE],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )\n",
        "\n",
        "def helper_fct_return_optimizer_w_learn_rate(opt_name:str,lr:float):\n",
        "  if opt_name == \"sgd\":\n",
        "    return tf.keras.optimizers.SGD(learning_rate=lr)\n",
        "  if opt_name == \"adam\":\n",
        "    return tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "  return \"error\"\n",
        "\n",
        "def train_test_model(hparams,run_dir):\n",
        "  body = tf.keras.models.Sequential()\n",
        "  for _ in range(int(hparams[HP_NUM_LAYERS])):\n",
        "    body.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS]))\n",
        "      # tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
        "  body.add(tf.keras.layers.Dense(1))\n",
        "  model = body\n",
        "  model.compile(\n",
        "      optimizer=helper_fct_return_optimizer_w_learn_rate(hparams[HP_OPTIMIZER],hparams[HP_LR],),\n",
        "      loss='BinaryCrossentropy', metrics=['accuracy'],)\n",
        "  model.fit(x_train, y_train,validation_data=(x_valid,y_valid),epochs=1, shuffle=True,verbose=False, callbacks=[ tf.keras.callbacks.TensorBoard(log_dir=run_dir+'_'+str(hparams[HP_NUM_LAYERS])+'layers_'+str(hparams[HP_NUM_UNITS])+'nodes_'+hparams[HP_OPTIMIZER]+str(hparams[HP_LR])+'_'+str(hparams[HP_BATCH_SIZE])+'batchsize_', histogram_freq=1)],batch_size=(hparams[HP_BATCH_SIZE])) \n",
        "  _, accuracy = model.evaluate(x_valid, y_valid,verbose=False)\n",
        "  return accuracy\n",
        "\n",
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams,run_dir)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
        "\n",
        "session_num = 0\n",
        "for num_units in tqdm(HP_NUM_UNITS.domain.values):\n",
        "  for num_layers in HP_NUM_LAYERS.domain.values:\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      for lr in HP_LR.domain.values:   \n",
        "        for batch_size in HP_BATCH_SIZE.domain.values:\n",
        "          hparams = {HP_NUM_UNITS: num_units,HP_NUM_LAYERS: num_layers, HP_OPTIMIZER: optimizer, HP_LR: lr, HP_BATCH_SIZE: batch_size }\n",
        "          run_name = \"run-%d\" % session_num\n",
        "          run(log_name+ run_name, hparams )\n",
        "          session_num += 1\n",
        "          # problem anschauen dass wenn script druch cpu und memory immer voll\n",
        "\n",
        "# tb in browser:\n",
        "print(\"tensorboard --logdir \"+log_name[:20]+\" --port \"+log_name[14:18])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensorboard --logdir logs_20220606-124205 --port 1242\n"
          ]
        }
      ],
      "source": [
        "print(\"tensorboard --logdir \"+log_name[:20]+\" --port \"+log_name[14:18])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "hyperparameter_tuning_with_hparams.ipynb",
      "toc_visible": true
    },
    "interpreter": {
      "hash": "bfc94bcae228bf04bdf8eb69576e966772fc4bd458c711e879fff003de93ac3f"
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('venvhparams': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
